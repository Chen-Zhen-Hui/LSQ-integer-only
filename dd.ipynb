{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_711466/1156956625.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'./qat_logs/cifar10/tiny_vgg_w{q_b}a{q_b}/checkpoint_max.pth')['net'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from models.tiny_vgg import TinyVGG\n",
    "from models.module import QLinear,QConv2d, fake_quantize_tensor,quantize_tensor,dequantize_tensor\n",
    "def cmp(a,b):\n",
    "    return (a-b).abs().max()\n",
    "q_b=8\n",
    "model = TinyVGG(image_size=32,num_classes=10)\n",
    "model.eval()\n",
    "model.fuse_bn()\n",
    "model.quantize(w_num_bits=q_b,a_num_bits=q_b)\n",
    "model.load_state_dict(torch.load(f'./qat_logs/cifar10/tiny_vgg_w{q_b}a{q_b}/checkpoint_max.pth')['net'])\n",
    "q_model = copy.deepcopy(model)\n",
    "q_model.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_conv = q_model.stage1.conv1.conv_module\n",
    "conv = model.stage1.conv1.conv_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "cmp(model.stage1.conv0(dummy_input), q_model.stage1.conv0(dummy_input))\n",
    "s1c0=F.relu(model.stage1.conv0(dummy_input))\n",
    "\n",
    "q_s1c0 = q_model.stage1.conv0.qo.quantize_tensor(s1c0)\n",
    "\n",
    "s1c1 = (model.stage1.conv1(s1c0))\n",
    "q_s1c1 = (q_model.stage1.conv1.quantize_inference_integer(q_s1c0))\n",
    "q_s1c1 = q_model.stage1.conv1.qo.dequantize_tensor(q_s1c1)\n",
    "cmp(s1c1,q_s1c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8610e-06, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_res = F.conv2d(q_s1c0, q_model.stage1.conv1.conv_module.weight, q_model.stage1.conv1.conv_module.bias,\n",
    "                     q_model.stage1.conv1.conv_module.stride, q_model.stage1.conv1.conv_module.padding,\n",
    "                     q_model.stage1.conv1.conv_module.dilation, q_model.stage1.conv1.conv_module.groups)\n",
    "\n",
    "\n",
    "q_weight = model.stage1.conv1.qw.fake_quantize(model.stage1.conv1.conv_module.weight)\n",
    "bias_scale = model.stage1.conv1.qw.alpha * model.stage1.conv0.qo.alpha\n",
    "q_bias = fake_quantize_tensor(model.stage1.conv1.conv_module.bias.float(), bias_scale, 32)\n",
    "\n",
    "res = F.conv2d(s1c0, q_weight, q_bias, \n",
    "                    model.stage1.conv1.conv_module.stride, model.stage1.conv1.conv_module.padding,\n",
    "                    model.stage1.conv1.conv_module.dilation, model.stage1.conv1.conv_module.groups)\n",
    "\n",
    "cmp(dequantize_tensor(q_res,q_model.stage1.conv1.qi.alpha*q_model.stage1.conv1.qw.alpha),res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4242, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp(q_res,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.6467e-01, -5.1973e-01,  6.2731e-01,  6.0706e-01, -1.4062e-04,\n",
       "         6.6373e-01, -7.5372e-01,  8.1981e-01,  1.5398e-01, -1.2037e-01,\n",
       "         6.5684e-01,  0.0000e+00,  8.2221e-01, -1.9841e-01, -2.1177e-01,\n",
       "        -1.0800e-01, -1.4062e-04,  0.0000e+00,  8.8028e-02, -6.4123e-02,\n",
       "        -5.4982e-02,  4.2313e-01,  1.9827e-01,  1.9574e-01, -2.8321e-01,\n",
       "        -4.2186e-02, -6.4545e-02,  1.5342e-01,  5.4842e-03,  2.6338e-01,\n",
       "         3.8235e-01, -1.3921e-02], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequantize_tensor(q_model.stage1.conv1.conv_module.bias,q_model.stage1.conv1.qi.alpha*q_model.stage1.conv1.qw.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 1.6470e-01, -5.1968e-01,  6.2731e-01,  6.0706e-01, -1.0251e-04,\n",
       "         6.6372e-01, -7.5367e-01,  8.1986e-01,  1.5396e-01, -1.2041e-01,\n",
       "         6.5689e-01, -5.6327e-05,  8.2221e-01, -1.9844e-01, -2.1176e-01,\n",
       "        -1.0802e-01, -1.1255e-04, -6.5899e-05,  8.8008e-02, -6.4127e-02,\n",
       "        -5.4944e-02,  4.2319e-01,  1.9827e-01,  1.9572e-01, -2.8318e-01,\n",
       "        -4.2248e-02, -6.4487e-02,  1.5344e-01,  5.5433e-03,  2.6343e-01,\n",
       "         3.8237e-01, -1.3874e-02], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stage1.conv1.conv_module.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ -6., -17.,  -9.],\n",
       "          [  0.,  66., -35.],\n",
       "          [ -1., -34.,  24.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  0.,  -4.,  -4.],\n",
       "          [ -2.,  -3.,  -5.],\n",
       "          [ 24., -19.,   4.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[  1.,   3.,  -3.],\n",
       "          [  3.,  -3.,  -8.],\n",
       "          [  1.,   4.,   3.]]],\n",
       "\n",
       "\n",
       "        [[[-11.,   2.,   0.],\n",
       "          [ 19.,  32., -21.],\n",
       "          [ 15.,  15., -40.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  2.,   5.,  11.],\n",
       "          [  6.,   3.,   7.],\n",
       "          [  4.,  -1.,   8.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[ 17.,  17.,  16.],\n",
       "          [  0., -26., -19.],\n",
       "          [  7., -24., -17.]]],\n",
       "\n",
       "\n",
       "        [[[ 19.,   0., -20.],\n",
       "          [-10., -12.,  -5.],\n",
       "          [ -3., -10.,   2.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 12.,  12.,   2.],\n",
       "          [  1.,  -8.,   5.],\n",
       "          [-10., -19., -15.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[ 19.,  25.,  34.],\n",
       "          [  1.,  -5.,   3.],\n",
       "          [-23., -40.,  -5.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-16.,  -8.,  -9.],\n",
       "          [-27.,   1.,  15.],\n",
       "          [ -2.,   8.,  -1.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -5.,   3.,  -2.],\n",
       "          [ -5.,   3., -10.],\n",
       "          [  3.,   6., -11.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[  8.,  -7.,   8.],\n",
       "          [  1.,  -9.,  12.],\n",
       "          [  6.,  -4.,  -8.]]],\n",
       "\n",
       "\n",
       "        [[[ -8., -25., -13.],\n",
       "          [ -5., -29., -36.],\n",
       "          [  0.,  -3.,   2.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -4.,  -1.,   3.],\n",
       "          [ -8.,  -5.,  14.],\n",
       "          [ -5.,  -7.,   9.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[-10.,   6.,  10.],\n",
       "          [-11.,   0.,   0.],\n",
       "          [-14.,  -3.,  15.]]],\n",
       "\n",
       "\n",
       "        [[[ -4.,  -4.,  16.],\n",
       "          [-10.,   0.,  10.],\n",
       "          [  1.,  18.,  -2.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  4.,  -1.,   1.],\n",
       "          [ 15.,  -8., -14.],\n",
       "          [ -4., -14.,  -4.]],\n",
       "\n",
       "         [[  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.],\n",
       "          [  0.,   0.,   0.]],\n",
       "\n",
       "         [[ 24.,  -4.,   2.],\n",
       "          [ 93., -41., -93.],\n",
       "          [ 39., -24., -23.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0034, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp(conv.weight,q_model.stage1.conv1.qw.dequantize_tensor(q_conv.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp(model.stage1.conv1.qw.fake_quantize(conv.weight),q_model.stage1.conv1.qw.dequantize_tensor(q_conv.weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(0.0209, requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model.stage1.conv1.qi.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(0.0209, requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stage1.conv0.qo.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
